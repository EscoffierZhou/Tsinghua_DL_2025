{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2dc0c4a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "91a04155783901da96bbe67b7a5e64bd",
     "grade": false,
     "grade_id": "cell-a336e6ffe0bd52b7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Deep Learning Coding Project 2: Image Classification\n",
    "\n",
    "Before we start, please put your **Chinese** name and student ID in following format:\n",
    "\n",
    "Name, 0000000000 // e.g.) 傅炜, 2021123123"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a648ddc",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "933b227c504b89bf0c43186e8d0e39a1",
     "grade": true,
     "grade_id": "cell-13ce984a5d4a067a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7468705d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cdd86b19ae7e03e9618718ef3c6ea9a0",
     "grade": false,
     "grade_id": "cell-a68075035123f58c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "We will use Python 3, [NumPy](https://numpy.org/), and [PyTorch](https://pytorch.org/) for this coding project. The example code has been tested under the latest stable release version.\n",
    "\n",
    "### Task\n",
    "\n",
    "In this notebook, you need to train a model to classify images. Given an image, you need to distinguish its category,\n",
    "e.g., whether it is a horse or an automobile. There are total 10 classes:\n",
    "airplane, automobile, bird, cat, deer, dog, frog, horse, ship and truck. We\n",
    "release 40,000 images for training, 10,000 images for validation. Each image has\n",
    "a shape of (3, 128, 128). We will evaluate your model in 10,000 images on the test set.\n",
    "\n",
    "Download the dataset from [here](https://cloud.tsinghua.edu.cn/d/00e0704738e04d32978b/) and organize them into a folder named \"cifar_10_4x\".\n",
    "\n",
    "<!-- Images can be classified as \"No Finding\" or **one or more types**. In the basic task, given an image, you only need to tell whether the X-ray indicates \"Infiltration\". In the bonus task, you need to tell whether *each* of the diseases exists.\n",
    "\n",
    "Images are taken from the [ChestX-ray14 dataset](https://www.kaggle.com/nih-chest-xrays/data) and downsampled to (256, 256). We release 44872 gray scale images for training and validation. We will evaluate your model on 10285 images in the test set. The dataset is available [here](https://cloud.tsinghua.edu.cn/d/16d06a89c5b4459db703/) and organized as follows: `train` directory includes all images for training and validation, and each line of `train.txt` records the labels separated by \"|\". -->\n",
    "\n",
    "### Coding\n",
    "\n",
    "We provide a code template. You can add new cells and modify our example to train your own model. To run this code, you should:\n",
    "\n",
    "+ implement your model (named `Net`) in `model.py`.\n",
    "+ implement your training loop in this notebook\n",
    "\n",
    "Your final submitted model should not be larger than **20M**. **Using any pretrained model is NOT permitted**.\n",
    "Besides, before you submit your result, **make sure you can test your model using our evaluation cell.** Name your best model \"cifar10_4x_best.pth\".\n",
    "\n",
    "### Report & Submission\n",
    "\n",
    "Your report should include:\n",
    "\n",
    "1. the details of your model\n",
    "2. all the hyper-parameters\n",
    "3. all the tricks or training techniques you use\n",
    "4. the training curve of your submitted model.\n",
    "\n",
    "Reporting additional ablation studies and how you improve your model are also encouraged.\n",
    "\n",
    "You should submit:\n",
    "\n",
    "+ all codes\n",
    "+ the model checkpoint (only \"cifar10_4x_best.pth\")\n",
    "+ your report (a separate \"pdf\")\n",
    "\n",
    "to web learning. We will use the evaluation code in this notebook to evaluate your model on the test set.\n",
    "\n",
    "### Grading\n",
    "\n",
    "We will grade this coding project based on the performance of your model (70%) and your report (30%). Regarding the evaluation metric of your model, assume your test accuracy is $X$, then your score is\n",
    "\n",
    "$\\frac{min(X,H)−0.6}{H−0.6}×7$\n",
    "\n",
    "where $H$ is accuracy of the model trained by TAs and $H=0.9$, i.e., you will get the full score if your test accuracy is above 90%.\n",
    "\n",
    "**Bonus**: The best submission with the highest testing accuracy will get 1 bonus point for the final course grade.\n",
    "\n",
    "**Avoid plagiarism! Any student who violates academic integrity will be seriously dealt with and receive an F for the course.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f6d8c7",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1ec5655a0d789db88709122c2a0ce6c9",
     "grade": false,
     "grade_id": "cell-4cee29f989d84cdc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Code Template\n",
    "\n",
    "We have masked the the training loop in this notebook for you to complete. You should also overwrite \"model.py\" and implement your own model."
   ]
  },
  {
   "cell_type": "code",
   "id": "d8c2354b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b34bc8b23f9c8e480a9671ef3453e7ac",
     "grade": false,
     "grade_id": "cell-a551fcc5ff27fb87",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2025-08-01T07:17:35.904738Z",
     "start_time": "2025-08-01T07:17:35.781Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "62b4fcaa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4367d7a728b91da35685f558363c4d66",
     "grade": false,
     "grade_id": "cell-ce69007d45b9103b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Setup Code\n",
    "\n",
    "If you use Colab in this coding project, please uncomment the code, fill the `GOOGLE_DRIVE_PATH_AFTER_MYDRIVE` and run the following cells to mount your Google drive. Then, the notebook can find the required file. If you run the notebook locally, you can skip the following cells."
   ]
  },
  {
   "cell_type": "code",
   "id": "785a7720",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T06:47:00.100426Z",
     "start_time": "2025-08-01T06:47:00.064059Z"
    }
   },
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "ca391e22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T06:47:00.464966Z",
     "start_time": "2025-08-01T06:47:00.400349Z"
    }
   },
   "source": [
    "# import os\n",
    "\n",
    "# # TODO: Fill in the Google Drive path where you uploaded the assignment\n",
    "# # Example: If you create a 2022SP folder and put all the files under CP1 folder, then '2022SP/CP1'\n",
    "# # GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = '2022SP/CP1'\n",
    "# GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = None \n",
    "# GOOGLE_DRIVE_PATH = os.path.join('drive', 'MyDrive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n",
    "# print(os.listdir(GOOGLE_DRIVE_PATH))"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "c62c2445",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T06:47:00.539275Z",
     "start_time": "2025-08-01T06:47:00.503037Z"
    }
   },
   "source": [
    "# import sys\n",
    "# sys.path.append(GOOGLE_DRIVE_PATH)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "2a227e03",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b7e3bc021f202881dd19297b1144711",
     "grade": false,
     "grade_id": "cell-e11eaf041d72deda",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2025-08-01T07:17:43.712988Z",
     "start_time": "2025-08-01T07:17:43.591780Z"
    }
   },
   "source": [
    "from dataset import CIFAR10_4x\n",
    "from evaluation import evaluation\n",
    "\n",
    "from model import Net  # this should be implemented by yourself"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "01370c88",
   "metadata": {},
   "source": [
    "### Enjoy Your Coding Time!"
   ]
  },
  {
   "cell_type": "code",
   "id": "8ca3c36d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T07:17:45.876022Z",
     "start_time": "2025-08-01T07:17:45.755619Z"
    }
   },
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    seed = int(seed)\n",
    "    if seed < 0 or seed > (2**32 - 1):\n",
    "        raise ValueError(\"Seed must be between 0 and 2**32 - 1\")\n",
    "    else:\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "set_seed(16)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "ed366135",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T07:17:51.098113Z",
     "start_time": "2025-08-01T07:17:46.957438Z"
    }
   },
   "source": [
    "data_root_dir = '.'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([125 / 255, 124 / 255, 115 / 255],\n",
    "                         [60 / 255, 59 / 255, 64 / 255])\n",
    "])\n",
    "\n",
    "trainset = CIFAR10_4x(root=data_root_dir,\n",
    "                      split=\"train\", transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=32, shuffle=True, num_workers=8, pin_memory=True)\n",
    "\n",
    "validset = CIFAR10_4x(root=data_root_dir,\n",
    "                      split='valid', transform=transform)\n",
    "validloader = torch.utils.data.DataLoader(\n",
    "    validset, batch_size=128, shuffle=False, num_workers=8)\n",
    "\n",
    "net = Net()\n",
    "print(\"number of trained parameters: %d\" % (\n",
    "    sum([param.nelement() for param in net.parameters() if param.requires_grad])))\n",
    "print(\"number of total parameters: %d\" %\n",
    "      (sum([param.nelement() for param in net.parameters()])))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "net.to(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of trained parameters: 48938\n",
      "number of total parameters: 48938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv3): Conv2d(12, 16, kernel_size=(5, 5), stride=(3, 3))\n",
       "  (fc1): Linear(in_features=256, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "c9e88bf8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-01T07:17:54.102969Z",
     "start_time": "2025-08-01T07:17:53.920062Z"
    }
   },
   "source": [
    "model_dir = '.'\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "torch.save(net, os.path.join(model_dir, 'cifar10_4x_0.pth'))\n",
    "\n",
    "# check the model size\n",
    "os.system(' '.join(['du', '-h', os.path.join(model_dir, 'cifar10_4x_0.pth')]))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "45e11f0a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9c6c195145fd44d054849497f0be5e3",
     "grade": false,
     "grade_id": "cell-2ea063d5855124d3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2025-08-01T07:28:39.174696100Z",
     "start_time": "2025-08-01T07:17:56.742601Z"
    }
   },
   "source": [
    "##############################################################################\n",
    "#                  TODO: You need to complete the code here                  #\n",
    "##############################################################################\n",
    "# YOUR CODE HERE\n",
    "# --- 准备工作 ---\n",
    "# 确保模型保存的目录存在\n",
    "model_save_dir = \"./models\"\n",
    "if not os.path.exists(model_save_dir):\n",
    "    os.makedirs(model_save_dir)\n",
    "model_path = os.path.join(model_save_dir, \"cifar10_4x_best.pth\")\n",
    "\n",
    "# --- 训练参数 ---\n",
    "num_epochs = 20  # 您可以根据需要调整训练轮数\n",
    "best_valid_accuracy = 0.0  # 用于记录最佳验证准确率\n",
    "\n",
    "print(\"开始训练...\")\n",
    "\n",
    "# --- 训练循环 ---\n",
    "for epoch in range(num_epochs):\n",
    "    # --- 训练阶段 ---\n",
    "    net.train()  # 将模型设置为训练模式\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # 获取输入数据；data 是一个 [inputs, labels] 的列表\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        # 前向传播 + 反向传播 + 优化\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # 打印统计信息\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:    # 每 100 个 mini-batches 打印一次\n",
    "            print(f'[Epoch {epoch + 1}, Batch {i + 1:5d}] 训练损失: {running_loss / 100:.3f}')\n",
    "            running_loss = 0.0\n",
    "\n",
    "    net.eval()  \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    valid_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in validloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            valid_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    current_accuracy = 100 * correct / total\n",
    "    avg_valid_loss = valid_loss / len(validloader)\n",
    "    print(f'Epoch {epoch + 1} 结束 | '\n",
    "          f'验证损失: {avg_valid_loss:.3f} | '\n",
    "          f'验证准确率: {current_accuracy:.2f} %')\n",
    "\n",
    "    # --- 保存最佳模型 ---\n",
    "    if current_accuracy > best_valid_accuracy:\n",
    "        best_valid_accuracy = current_accuracy\n",
    "        torch.save(net, model_path)\n",
    "        print(f'检测到新的最佳模型！已保存到 {model_path}')\n",
    "\n",
    "print('训练完成!')\n",
    "print(f'最佳验证准确率为: {best_valid_accuracy:.2f} %')\n",
    "##############################################################################\n",
    "#                              END OF YOUR CODE                              #\n",
    "##############################################################################"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始训练...\n",
      "[Epoch 1, Batch   100] 训练损失: 2.049\n",
      "[Epoch 1, Batch   200] 训练损失: 1.813\n",
      "[Epoch 1, Batch   300] 训练损失: 1.693\n",
      "[Epoch 1, Batch   400] 训练损失: 1.612\n",
      "[Epoch 1, Batch   500] 训练损失: 1.518\n",
      "[Epoch 1, Batch   600] 训练损失: 1.506\n",
      "[Epoch 1, Batch   700] 训练损失: 1.458\n",
      "[Epoch 1, Batch   800] 训练损失: 1.422\n",
      "[Epoch 1, Batch   900] 训练损失: 1.390\n",
      "[Epoch 1, Batch  1000] 训练损失: 1.346\n",
      "[Epoch 1, Batch  1100] 训练损失: 1.333\n",
      "[Epoch 1, Batch  1200] 训练损失: 1.324\n",
      "Epoch 1 结束 | 验证损失: 1.256 | 验证准确率: 55.75 %\n",
      "检测到新的最佳模型！已保存到 ./models\\cifar10_4x_best.pth\n",
      "[Epoch 2, Batch   100] 训练损失: 1.218\n",
      "[Epoch 2, Batch   200] 训练损失: 1.225\n",
      "[Epoch 2, Batch   300] 训练损失: 1.196\n",
      "[Epoch 2, Batch   400] 训练损失: 1.188\n",
      "[Epoch 2, Batch   500] 训练损失: 1.160\n",
      "[Epoch 2, Batch   600] 训练损失: 1.166\n",
      "[Epoch 2, Batch   700] 训练损失: 1.140\n",
      "[Epoch 2, Batch   800] 训练损失: 1.131\n",
      "[Epoch 2, Batch   900] 训练损失: 1.127\n",
      "[Epoch 2, Batch  1000] 训练损失: 1.155\n",
      "[Epoch 2, Batch  1100] 训练损失: 1.107\n",
      "[Epoch 2, Batch  1200] 训练损失: 1.073\n",
      "Epoch 2 结束 | 验证损失: 1.093 | 验证准确率: 61.50 %\n",
      "检测到新的最佳模型！已保存到 ./models\\cifar10_4x_best.pth\n",
      "[Epoch 3, Batch   100] 训练损失: 1.016\n",
      "[Epoch 3, Batch   200] 训练损失: 1.024\n",
      "[Epoch 3, Batch   300] 训练损失: 1.041\n",
      "[Epoch 3, Batch   400] 训练损失: 0.970\n",
      "[Epoch 3, Batch   500] 训练损失: 1.035\n",
      "[Epoch 3, Batch   600] 训练损失: 1.027\n",
      "[Epoch 3, Batch   700] 训练损失: 1.005\n",
      "[Epoch 3, Batch   800] 训练损失: 0.994\n",
      "[Epoch 3, Batch   900] 训练损失: 0.973\n",
      "[Epoch 3, Batch  1000] 训练损失: 0.995\n",
      "[Epoch 3, Batch  1100] 训练损失: 0.990\n",
      "[Epoch 3, Batch  1200] 训练损失: 0.951\n",
      "Epoch 3 结束 | 验证损失: 1.014 | 验证准确率: 64.92 %\n",
      "检测到新的最佳模型！已保存到 ./models\\cifar10_4x_best.pth\n",
      "[Epoch 4, Batch   100] 训练损失: 0.892\n",
      "[Epoch 4, Batch   200] 训练损失: 0.898\n",
      "[Epoch 4, Batch   300] 训练损失: 0.903\n",
      "[Epoch 4, Batch   400] 训练损失: 0.893\n",
      "[Epoch 4, Batch   500] 训练损失: 0.894\n",
      "[Epoch 4, Batch   600] 训练损失: 0.911\n",
      "[Epoch 4, Batch   700] 训练损失: 0.919\n",
      "[Epoch 4, Batch   800] 训练损失: 0.871\n",
      "[Epoch 4, Batch   900] 训练损失: 0.908\n",
      "[Epoch 4, Batch  1000] 训练损失: 0.910\n",
      "[Epoch 4, Batch  1100] 训练损失: 0.933\n",
      "[Epoch 4, Batch  1200] 训练损失: 0.925\n",
      "Epoch 4 结束 | 验证损失: 0.965 | 验证准确率: 66.51 %\n",
      "检测到新的最佳模型！已保存到 ./models\\cifar10_4x_best.pth\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 23\u001B[0m\n\u001B[0;32m     21\u001B[0m net\u001B[38;5;241m.\u001B[39mtrain()  \u001B[38;5;66;03m# 将模型设置为训练模式\u001B[39;00m\n\u001B[0;32m     22\u001B[0m running_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[1;32m---> 23\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrainloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m:\n\u001B[0;32m     24\u001B[0m     \u001B[38;5;66;03m# 获取输入数据；data 是一个 [inputs, labels] 的列表\u001B[39;00m\n\u001B[0;32m     25\u001B[0m     inputs, labels \u001B[38;5;241m=\u001B[39m data\n\u001B[0;32m     26\u001B[0m     inputs, labels \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device), labels\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[1;32mF:\\Anaconda\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:493\u001B[0m, in \u001B[0;36mDataLoader.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    491\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator\n\u001B[0;32m    492\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 493\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mF:\\Anaconda\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:424\u001B[0m, in \u001B[0;36mDataLoader._get_iterator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    422\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    423\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_worker_number_rationality()\n\u001B[1;32m--> 424\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_MultiProcessingDataLoaderIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mF:\\Anaconda\\envs\\pytorch\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1171\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter.__init__\u001B[1;34m(self, loader)\u001B[0m\n\u001B[0;32m   1164\u001B[0m w\u001B[38;5;241m.\u001B[39mdaemon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1165\u001B[0m \u001B[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001B[39;00m\n\u001B[0;32m   1166\u001B[0m \u001B[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001B[39;00m\n\u001B[0;32m   1167\u001B[0m \u001B[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001B[39;00m\n\u001B[0;32m   1168\u001B[0m \u001B[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001B[39;00m\n\u001B[0;32m   1169\u001B[0m \u001B[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001B[39;00m\n\u001B[0;32m   1170\u001B[0m \u001B[38;5;66;03m#     AssertionError: can only join a started process.\u001B[39;00m\n\u001B[1;32m-> 1171\u001B[0m \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1172\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_queues\u001B[38;5;241m.\u001B[39mappend(index_queue)\n\u001B[0;32m   1173\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers\u001B[38;5;241m.\u001B[39mappend(w)\n",
      "File \u001B[1;32mF:\\Anaconda\\envs\\pytorch\\Lib\\multiprocessing\\process.py:121\u001B[0m, in \u001B[0;36mBaseProcess.start\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _current_process\u001B[38;5;241m.\u001B[39m_config\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemon\u001B[39m\u001B[38;5;124m'\u001B[39m), \\\n\u001B[0;32m    119\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemonic processes are not allowed to have children\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    120\u001B[0m _cleanup()\n\u001B[1;32m--> 121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sentinel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen\u001B[38;5;241m.\u001B[39msentinel\n\u001B[0;32m    123\u001B[0m \u001B[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001B[39;00m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;66;03m# reference to the process object (see bpo-30775)\u001B[39;00m\n",
      "File \u001B[1;32mF:\\Anaconda\\envs\\pytorch\\Lib\\multiprocessing\\context.py:224\u001B[0m, in \u001B[0;36mProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[1;32m--> 224\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mProcess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mF:\\Anaconda\\envs\\pytorch\\Lib\\multiprocessing\\context.py:337\u001B[0m, in \u001B[0;36mSpawnProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    334\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    335\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[0;32m    336\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpopen_spawn_win32\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Popen\n\u001B[1;32m--> 337\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mF:\\Anaconda\\envs\\pytorch\\Lib\\multiprocessing\\popen_spawn_win32.py:95\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[1;34m(self, process_obj)\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     94\u001B[0m     reduction\u001B[38;5;241m.\u001B[39mdump(prep_data, to_child)\n\u001B[1;32m---> 95\u001B[0m     \u001B[43mreduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mto_child\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     97\u001B[0m     set_spawning_popen(\u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[1;32mF:\\Anaconda\\envs\\pytorch\\Lib\\multiprocessing\\reduction.py:60\u001B[0m, in \u001B[0;36mdump\u001B[1;34m(obj, file, protocol)\u001B[0m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mdump\u001B[39m(obj, file, protocol\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m     59\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001B[39;00m\n\u001B[1;32m---> 60\u001B[0m     \u001B[43mForkingPickler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprotocol\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdump\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "e793356d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "885b0bf12e9c21f035c6df6199532ea9",
     "grade": false,
     "grade_id": "cell-a25d638df48b13bc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "Before submission, please run the following cell to make sure your model can be correctly graded."
   ]
  },
  {
   "cell_type": "code",
   "id": "6b631827",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36e31059e96008e349a5ef3bccc487eb",
     "grade": false,
     "grade_id": "cell-3121e7d50ff7793b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2025-08-01T07:30:36.504466Z",
     "start_time": "2025-08-01T07:30:09.223455Z"
    }
   },
   "source": [
    "!python evaluation.py\n",
    "# net = torch.load(os.path.join(base_dir, \"models/cifar10_4x_best.pth\"))\n",
    "# 这里直接加载了整个的模型对象\n",
    "# torch.save(net.state_dict(), model_path) 这是仅保存参数的代码\n",
    "# torch.save(net, model_path) 这是保存完整架构的代码"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of trained parameters: 48938\n",
      "number of total parameters: 48938\n",
      "can't load test set because [Errno 2] No such file or directory: 'F:\\\\desktop\\\\CodingProject2\\\\CodingProject2\\\\cifar_10_4x\\\\test', load valid set now\n",
      "Accuracy of the network on the valid images: 66 %\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
